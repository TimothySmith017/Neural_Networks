{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   Age Attrition     BusinessTravel  DailyRate              Department  \\\n0   41       Yes      Travel_Rarely       1102                   Sales   \n1   49        No  Travel_Frequently        279  Research & Development   \n2   37       Yes      Travel_Rarely       1373  Research & Development   \n3   33        No  Travel_Frequently       1392  Research & Development   \n4   27        No      Travel_Rarely        591  Research & Development   \n\n   DistanceFromHome  Education EducationField  EmployeeCount  EmployeeNumber  \\\n0                 1          2  Life Sciences              1               1   \n1                 8          1  Life Sciences              1               2   \n2                 2          2          Other              1               4   \n3                 3          4  Life Sciences              1               5   \n4                 2          1        Medical              1               7   \n\n   ...  RelationshipSatisfaction StandardHours  StockOptionLevel  \\\n0  ...                         1            80                 0   \n1  ...                         4            80                 1   \n2  ...                         2            80                 0   \n3  ...                         3            80                 0   \n4  ...                         4            80                 1   \n\n   TotalWorkingYears  TrainingTimesLastYear WorkLifeBalance  YearsAtCompany  \\\n0                  8                      0               1               6   \n1                 10                      3               3              10   \n2                  7                      3               3               0   \n3                  8                      3               3               8   \n4                  6                      3               3               2   \n\n  YearsInCurrentRole  YearsSinceLastPromotion  YearsWithCurrManager  \n0                  4                        0                     5  \n1                  7                        1                     7  \n2                  0                        0                     0  \n3                  7                        3                     0  \n4                  2                        2                     2  \n\n[5 rows x 35 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>Attrition</th>\n      <th>BusinessTravel</th>\n      <th>DailyRate</th>\n      <th>Department</th>\n      <th>DistanceFromHome</th>\n      <th>Education</th>\n      <th>EducationField</th>\n      <th>EmployeeCount</th>\n      <th>EmployeeNumber</th>\n      <th>...</th>\n      <th>RelationshipSatisfaction</th>\n      <th>StandardHours</th>\n      <th>StockOptionLevel</th>\n      <th>TotalWorkingYears</th>\n      <th>TrainingTimesLastYear</th>\n      <th>WorkLifeBalance</th>\n      <th>YearsAtCompany</th>\n      <th>YearsInCurrentRole</th>\n      <th>YearsSinceLastPromotion</th>\n      <th>YearsWithCurrManager</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>41</td>\n      <td>Yes</td>\n      <td>Travel_Rarely</td>\n      <td>1102</td>\n      <td>Sales</td>\n      <td>1</td>\n      <td>2</td>\n      <td>Life Sciences</td>\n      <td>1</td>\n      <td>1</td>\n      <td>...</td>\n      <td>1</td>\n      <td>80</td>\n      <td>0</td>\n      <td>8</td>\n      <td>0</td>\n      <td>1</td>\n      <td>6</td>\n      <td>4</td>\n      <td>0</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>49</td>\n      <td>No</td>\n      <td>Travel_Frequently</td>\n      <td>279</td>\n      <td>Research &amp; Development</td>\n      <td>8</td>\n      <td>1</td>\n      <td>Life Sciences</td>\n      <td>1</td>\n      <td>2</td>\n      <td>...</td>\n      <td>4</td>\n      <td>80</td>\n      <td>1</td>\n      <td>10</td>\n      <td>3</td>\n      <td>3</td>\n      <td>10</td>\n      <td>7</td>\n      <td>1</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>37</td>\n      <td>Yes</td>\n      <td>Travel_Rarely</td>\n      <td>1373</td>\n      <td>Research &amp; Development</td>\n      <td>2</td>\n      <td>2</td>\n      <td>Other</td>\n      <td>1</td>\n      <td>4</td>\n      <td>...</td>\n      <td>2</td>\n      <td>80</td>\n      <td>0</td>\n      <td>7</td>\n      <td>3</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>33</td>\n      <td>No</td>\n      <td>Travel_Frequently</td>\n      <td>1392</td>\n      <td>Research &amp; Development</td>\n      <td>3</td>\n      <td>4</td>\n      <td>Life Sciences</td>\n      <td>1</td>\n      <td>5</td>\n      <td>...</td>\n      <td>3</td>\n      <td>80</td>\n      <td>0</td>\n      <td>8</td>\n      <td>3</td>\n      <td>3</td>\n      <td>8</td>\n      <td>7</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>27</td>\n      <td>No</td>\n      <td>Travel_Rarely</td>\n      <td>591</td>\n      <td>Research &amp; Development</td>\n      <td>2</td>\n      <td>1</td>\n      <td>Medical</td>\n      <td>1</td>\n      <td>7</td>\n      <td>...</td>\n      <td>4</td>\n      <td>80</td>\n      <td>1</td>\n      <td>6</td>\n      <td>3</td>\n      <td>3</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 35 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "# Import our input dataset\n",
    "attrition_df = pd.read_csv('HR-Employee-Attrition.csv')\n",
    "attrition_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate our categorical variable list\n",
    "attrition_cat = attrition_df.dtypes[attrition_df.dtypes == \"object\"].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Attrition         2\nBusinessTravel    3\nDepartment        3\nEducationField    6\nGender            2\nJobRole           9\nMaritalStatus     3\nOver18            1\nOverTime          2\ndtype: int64"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# Check the number of unique values in each column\n",
    "attrition_df[attrition_cat].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   Attrition_No  Attrition_Yes  BusinessTravel_Non-Travel  \\\n0           0.0            1.0                        0.0   \n1           1.0            0.0                        0.0   \n2           0.0            1.0                        0.0   \n3           1.0            0.0                        0.0   \n4           1.0            0.0                        0.0   \n\n   BusinessTravel_Travel_Frequently  BusinessTravel_Travel_Rarely  \\\n0                               0.0                           1.0   \n1                               1.0                           0.0   \n2                               0.0                           1.0   \n3                               1.0                           0.0   \n4                               0.0                           1.0   \n\n   Department_Human Resources  Department_Research & Development  \\\n0                         0.0                                0.0   \n1                         0.0                                1.0   \n2                         0.0                                1.0   \n3                         0.0                                1.0   \n4                         0.0                                1.0   \n\n   Department_Sales  EducationField_Human Resources  \\\n0               1.0                             0.0   \n1               0.0                             0.0   \n2               0.0                             0.0   \n3               0.0                             0.0   \n4               0.0                             0.0   \n\n   EducationField_Life Sciences  ...  JobRole_Research Director  \\\n0                           1.0  ...                        0.0   \n1                           1.0  ...                        0.0   \n2                           0.0  ...                        0.0   \n3                           1.0  ...                        0.0   \n4                           0.0  ...                        0.0   \n\n   JobRole_Research Scientist  JobRole_Sales Executive  \\\n0                         0.0                      1.0   \n1                         1.0                      0.0   \n2                         0.0                      0.0   \n3                         1.0                      0.0   \n4                         0.0                      0.0   \n\n   JobRole_Sales Representative  MaritalStatus_Divorced  \\\n0                           0.0                     0.0   \n1                           0.0                     0.0   \n2                           0.0                     0.0   \n3                           0.0                     0.0   \n4                           0.0                     0.0   \n\n   MaritalStatus_Married  MaritalStatus_Single  Over18_Y  OverTime_No  \\\n0                    0.0                   1.0       1.0          0.0   \n1                    1.0                   0.0       1.0          1.0   \n2                    0.0                   1.0       1.0          0.0   \n3                    1.0                   0.0       1.0          0.0   \n4                    1.0                   0.0       1.0          1.0   \n\n   OverTime_Yes  \n0           1.0  \n1           0.0  \n2           1.0  \n3           1.0  \n4           0.0  \n\n[5 rows x 31 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Attrition_No</th>\n      <th>Attrition_Yes</th>\n      <th>BusinessTravel_Non-Travel</th>\n      <th>BusinessTravel_Travel_Frequently</th>\n      <th>BusinessTravel_Travel_Rarely</th>\n      <th>Department_Human Resources</th>\n      <th>Department_Research &amp; Development</th>\n      <th>Department_Sales</th>\n      <th>EducationField_Human Resources</th>\n      <th>EducationField_Life Sciences</th>\n      <th>...</th>\n      <th>JobRole_Research Director</th>\n      <th>JobRole_Research Scientist</th>\n      <th>JobRole_Sales Executive</th>\n      <th>JobRole_Sales Representative</th>\n      <th>MaritalStatus_Divorced</th>\n      <th>MaritalStatus_Married</th>\n      <th>MaritalStatus_Single</th>\n      <th>Over18_Y</th>\n      <th>OverTime_No</th>\n      <th>OverTime_Yes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 31 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# Create a OneHotEncoder instance\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Fit and transform the OneHotEncoder using the categorical variable list\n",
    "encode_df = pd.DataFrame(enc.fit_transform(attrition_df[attrition_cat]))\n",
    "\n",
    "# Add the encoded variable names to the DataFrame\n",
    "encode_df.columns = enc.get_feature_names(attrition_cat)\n",
    "encode_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   Age  DailyRate  DistanceFromHome  Education  EmployeeCount  EmployeeNumber  \\\n0   41       1102                 1          2              1               1   \n1   49        279                 8          1              1               2   \n2   37       1373                 2          2              1               4   \n3   33       1392                 3          4              1               5   \n4   27        591                 2          1              1               7   \n\n   EnvironmentSatisfaction  HourlyRate  JobInvolvement  JobLevel  ...  \\\n0                        2          94               3         2  ...   \n1                        3          61               2         2  ...   \n2                        4          92               2         1  ...   \n3                        4          56               3         1  ...   \n4                        1          40               3         1  ...   \n\n   JobRole_Research Director  JobRole_Research Scientist  \\\n0                        0.0                         0.0   \n1                        0.0                         1.0   \n2                        0.0                         0.0   \n3                        0.0                         1.0   \n4                        0.0                         0.0   \n\n   JobRole_Sales Executive  JobRole_Sales Representative  \\\n0                      1.0                           0.0   \n1                      0.0                           0.0   \n2                      0.0                           0.0   \n3                      0.0                           0.0   \n4                      0.0                           0.0   \n\n   MaritalStatus_Divorced  MaritalStatus_Married  MaritalStatus_Single  \\\n0                     0.0                    0.0                   1.0   \n1                     0.0                    1.0                   0.0   \n2                     0.0                    0.0                   1.0   \n3                     0.0                    1.0                   0.0   \n4                     0.0                    1.0                   0.0   \n\n   Over18_Y  OverTime_No  OverTime_Yes  \n0       1.0          0.0           1.0  \n1       1.0          1.0           0.0  \n2       1.0          0.0           1.0  \n3       1.0          0.0           1.0  \n4       1.0          1.0           0.0  \n\n[5 rows x 57 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>DailyRate</th>\n      <th>DistanceFromHome</th>\n      <th>Education</th>\n      <th>EmployeeCount</th>\n      <th>EmployeeNumber</th>\n      <th>EnvironmentSatisfaction</th>\n      <th>HourlyRate</th>\n      <th>JobInvolvement</th>\n      <th>JobLevel</th>\n      <th>...</th>\n      <th>JobRole_Research Director</th>\n      <th>JobRole_Research Scientist</th>\n      <th>JobRole_Sales Executive</th>\n      <th>JobRole_Sales Representative</th>\n      <th>MaritalStatus_Divorced</th>\n      <th>MaritalStatus_Married</th>\n      <th>MaritalStatus_Single</th>\n      <th>Over18_Y</th>\n      <th>OverTime_No</th>\n      <th>OverTime_Yes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>41</td>\n      <td>1102</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>94</td>\n      <td>3</td>\n      <td>2</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>49</td>\n      <td>279</td>\n      <td>8</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>61</td>\n      <td>2</td>\n      <td>2</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>37</td>\n      <td>1373</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>4</td>\n      <td>4</td>\n      <td>92</td>\n      <td>2</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>33</td>\n      <td>1392</td>\n      <td>3</td>\n      <td>4</td>\n      <td>1</td>\n      <td>5</td>\n      <td>4</td>\n      <td>56</td>\n      <td>3</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>27</td>\n      <td>591</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>7</td>\n      <td>1</td>\n      <td>40</td>\n      <td>3</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 57 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# Merge one-hot encoded features and drop the originals\n",
    "attrition_df = attrition_df.merge(encode_df,left_index=True, right_index=True)\n",
    "attrition_df = attrition_df.drop(attrition_cat,1)\n",
    "attrition_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y= attrition_df[\"Attrition_Yes\"].values\n",
    "X = attrition_df.drop([\"Attrition_Yes\",\"Attrition_No\"],1).values\n",
    "\n",
    "#Split the processed data into test/train group\n",
    "X_train, X_test, y_train, y_test, = train_test_split(X,y, random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 8)                 448       \n_________________________________________________________________\ndense_1 (Dense)              (None, 5)                 45        \n_________________________________________________________________\ndense_2 (Dense)              (None, 1)                 6         \n=================================================================\nTotal params: 499\nTrainable params: 499\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "# Define the model - deep neural net\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 =  8\n",
    "hidden_nodes_layer2 = 5\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": " - accuracy: 0.8158\nEpoch 116/300\n1102/1102 [==============================] - 0s 68us/sample - loss: 0.4321 - accuracy: 0.8448\nEpoch 117/300\n1102/1102 [==============================] - 0s 70us/sample - loss: 0.4223 - accuracy: 0.8466\nEpoch 118/300\n1102/1102 [==============================] - 0s 73us/sample - loss: 0.4708 - accuracy: 0.8240\nEpoch 119/300\n1102/1102 [==============================] - 0s 69us/sample - loss: 0.3934 - accuracy: 0.8394\nEpoch 120/300\n1102/1102 [==============================] - 0s 69us/sample - loss: 0.4394 - accuracy: 0.8412\nEpoch 121/300\n1102/1102 [==============================] - 0s 69us/sample - loss: 0.3471 - accuracy: 0.8648\nEpoch 122/300\n1102/1102 [==============================] - 0s 70us/sample - loss: 1.0038 - accuracy: 0.7740\nEpoch 123/300\n1102/1102 [==============================] - 0s 68us/sample - loss: 0.8389 - accuracy: 0.8076\nEpoch 124/300\n1102/1102 [==============================] - 0s 69us/sample - loss: 0.5411 - accuracy: 0.8167\nEpoch 125/300\n1102/1102 [==============================] - 0s 60us/sample - loss: 0.6319 - accuracy: 0.8040\nEpoch 126/300\n1102/1102 [==============================] - 0s 80us/sample - loss: 0.5437 - accuracy: 0.8240\nEpoch 127/300\n1102/1102 [==============================] - 0s 70us/sample - loss: 0.9891 - accuracy: 0.7831\nEpoch 128/300\n1102/1102 [==============================] - 0s 65us/sample - loss: 1.0735 - accuracy: 0.7632\nEpoch 129/300\n1102/1102 [==============================] - 0s 65us/sample - loss: 0.4004 - accuracy: 0.8584\nEpoch 130/300\n1102/1102 [==============================] - 0s 67us/sample - loss: 0.5408 - accuracy: 0.8276\nEpoch 131/300\n1102/1102 [==============================] - 0s 69us/sample - loss: 0.5132 - accuracy: 0.8339\nEpoch 132/300\n1102/1102 [==============================] - 0s 70us/sample - loss: 0.6657 - accuracy: 0.8049\nEpoch 133/300\n1102/1102 [==============================] - 0s 67us/sample - loss: 0.8361 - accuracy: 0.7985\nEpoch 134/300\n1102/1102 [==============================] - 0s 67us/sample - loss: 0.8465 - accuracy: 0.7813\nEpoch 135/300\n1102/1102 [==============================] - 0s 66us/sample - loss: 0.3871 - accuracy: 0.8466\nEpoch 136/300\n1102/1102 [==============================] - 0s 69us/sample - loss: 0.5531 - accuracy: 0.8131\nEpoch 137/300\n1102/1102 [==============================] - 0s 86us/sample - loss: 0.5731 - accuracy: 0.8122\nEpoch 138/300\n1102/1102 [==============================] - 0s 70us/sample - loss: 0.4905 - accuracy: 0.8394\nEpoch 139/300\n1102/1102 [==============================] - 0s 69us/sample - loss: 0.5679 - accuracy: 0.8122\nEpoch 140/300\n1102/1102 [==============================] - 0s 72us/sample - loss: 0.3833 - accuracy: 0.8521\nEpoch 141/300\n1102/1102 [==============================] - 0s 74us/sample - loss: 0.4743 - accuracy: 0.8321\nEpoch 142/300\n1102/1102 [==============================] - 0s 75us/sample - loss: 0.4152 - accuracy: 0.8385\nEpoch 143/300\n1102/1102 [==============================] - 0s 74us/sample - loss: 0.3986 - accuracy: 0.8448\nEpoch 144/300\n1102/1102 [==============================] - 0s 75us/sample - loss: 0.4544 - accuracy: 0.8376\nEpoch 145/300\n1102/1102 [==============================] - 0s 74us/sample - loss: 0.3960 - accuracy: 0.8621\nEpoch 146/300\n1102/1102 [==============================] - 0s 73us/sample - loss: 0.4560 - accuracy: 0.8230\nEpoch 147/300\n1102/1102 [==============================] - 0s 77us/sample - loss: 0.4558 - accuracy: 0.8348\nEpoch 148/300\n1102/1102 [==============================] - 0s 80us/sample - loss: 0.4790 - accuracy: 0.8294\nEpoch 149/300\n1102/1102 [==============================] - 0s 77us/sample - loss: 0.4309 - accuracy: 0.8430\nEpoch 150/300\n1102/1102 [==============================] - 0s 80us/sample - loss: 0.3815 - accuracy: 0.8539\nEpoch 151/300\n1102/1102 [==============================] - 0s 69us/sample - loss: 0.3797 - accuracy: 0.8557\nEpoch 152/300\n1102/1102 [==============================] - 0s 65us/sample - loss: 0.4693 - accuracy: 0.8330\nEpoch 153/300\n1102/1102 [==============================] - 0s 64us/sample - loss: 0.5066 - accuracy: 0.8140\nEpoch 154/300\n1102/1102 [==============================] - 0s 64us/sample - loss: 0.4810 - accuracy: 0.8194\nEpoch 155/300\n1102/1102 [==============================] - 0s 68us/sample - loss: 0.4881 - accuracy: 0.8258\nEpoch 156/300\n1102/1102 [==============================] - 0s 66us/sample - loss: 0.4709 - accuracy: 0.8330\nEpoch 157/300\n1102/1102 [==============================] - 0s 66us/sample - loss: 0.4519 - accuracy: 0.8348\nEpoch 158/300\n1102/1102 [==============================] - 0s 68us/sample - loss: 0.4335 - accuracy: 0.8403\nEpoch 159/300\n1102/1102 [==============================] - 0s 71us/sample - loss: 0.9146 - accuracy: 0.7958\nEpoch 160/300\n1102/1102 [==============================] - 0s 70us/sample - loss: 0.5479 - accuracy: 0.8176\nEpoch 161/300\n1102/1102 [==============================] - 0s 69us/sample - loss: 0.4079 - accuracy: 0.8475\nEpoch 162/300\n1102/1102 [==============================] - 0s 64us/sample - loss: 0.5897 - accuracy: 0.8103\nEpoch 163/300\n1102/1102 [==============================] - 0s 66us/sample - loss: 0.5909 - accuracy: 0.8230\nEpoch 164/300\n1102/1102 [==============================] - 0s 74us/sample - loss: 0.5455 - accuracy: 0.7922\nEpoch 165/300\n1102/1102 [==============================] - 0s 70us/sample - loss: 0.8533 - accuracy: 0.7831\nEpoch 166/300\n1102/1102 [==============================] - 0s 67us/sample - loss: 0.5420 - accuracy: 0.8085\nEpoch 167/300\n1102/1102 [==============================] - 0s 71us/sample - loss: 0.5308 - accuracy: 0.8258\nEpoch 168/300\n1102/1102 [==============================] - 0s 68us/sample - loss: 0.4696 - accuracy: 0.8367\nEpoch 169/300\n1102/1102 [==============================] - 0s 69us/sample - loss: 0.4073 - accuracy: 0.8521\nEpoch 170/300\n1102/1102 [==============================] - 0s 68us/sample - loss: 0.3437 - accuracy: 0.8675\nEpoch 171/300\n1102/1102 [==============================] - 0s 67us/sample - loss: 0.7577 - accuracy: 0.7940\nEpoch 172/300\n1102/1102 [==============================] - 0s 63us/sample - loss: 0.5587 - accuracy: 0.8176\nEpoch 173/300\n1102/1102 [==============================] - 0s 63us/sample - loss: 0.5369 - accuracy: 0.8185\nEpoch 174/300\n1102/1102 [==============================] - 0s 67us/sample - loss: 0.4264 - accuracy: 0.8403\nEpoch 175/300\n1102/1102 [==============================] - 0s 71us/sample - loss: 0.3739 - accuracy: 0.8603\nEpoch 176/300\n1102/1102 [==============================] - 0s 70us/sample - loss: 0.4350 - accuracy: 0.8367\nEpoch 177/300\n1102/1102 [==============================] - 0s 67us/sample - loss: 0.4606 - accuracy: 0.8339\nEpoch 178/300\n1102/1102 [==============================] - 0s 64us/sample - loss: 0.4372 - accuracy: 0.8221\nEpoch 179/300\n1102/1102 [==============================] - 0s 62us/sample - loss: 0.4605 - accuracy: 0.8376\nEpoch 180/300\n1102/1102 [==============================] - 0s 62us/sample - loss: 0.6765 - accuracy: 0.8004\nEpoch 181/300\n1102/1102 [==============================] - 0s 65us/sample - loss: 0.5474 - accuracy: 0.8185\nEpoch 182/300\n1102/1102 [==============================] - 0s 80us/sample - loss: 0.4610 - accuracy: 0.8103\nEpoch 183/300\n1102/1102 [==============================] - 0s 69us/sample - loss: 0.3787 - accuracy: 0.8612\nEpoch 184/300\n1102/1102 [==============================] - 0s 67us/sample - loss: 0.4275 - accuracy: 0.8303\nEpoch 185/300\n1102/1102 [==============================] - 0s 79us/sample - loss: 0.4059 - accuracy: 0.8457\nEpoch 186/300\n1102/1102 [==============================] - 0s 74us/sample - loss: 0.4620 - accuracy: 0.8412\nEpoch 187/300\n1102/1102 [==============================] - 0s 73us/sample - loss: 0.4303 - accuracy: 0.8584\nEpoch 188/300\n1102/1102 [==============================] - 0s 71us/sample - loss: 0.4894 - accuracy: 0.8294\nEpoch 189/300\n1102/1102 [==============================] - 0s 69us/sample - loss: 0.3864 - accuracy: 0.8548\nEpoch 190/300\n1102/1102 [==============================] - 0s 76us/sample - loss: 0.5019 - accuracy: 0.8122\nEpoch 191/300\n1102/1102 [==============================] - 0s 71us/sample - loss: 0.4463 - accuracy: 0.8367\nEpoch 192/300\n1102/1102 [==============================] - 0s 71us/sample - loss: 0.3616 - accuracy: 0.8648\nEpoch 193/300\n1102/1102 [==============================] - 0s 71us/sample - loss: 0.3969 - accuracy: 0.8421\nEpoch 194/300\n1102/1102 [==============================] - 0s 68us/sample - loss: 0.4388 - accuracy: 0.8457\nEpoch 195/300\n1102/1102 [==============================] - 0s 69us/sample - loss: 0.5029 - accuracy: 0.8249\nEpoch 196/300\n1102/1102 [==============================] - 0s 68us/sample - loss: 0.5623 - accuracy: 0.8149\nEpoch 197/300\n1102/1102 [==============================] - 0s 62us/sample - loss: 0.8756 - accuracy: 0.7786\nEpoch 198/300\n1102/1102 [==============================] - 0s 65us/sample - loss: 0.7043 - accuracy: 0.7976\nEpoch 199/300\n1102/1102 [==============================] - 0s 64us/sample - loss: 0.4251 - accuracy: 0.8339\nEpoch 200/300\n1102/1102 [==============================] - 0s 65us/sample - loss: 0.3937 - accuracy: 0.8530\nEpoch 201/300\n1102/1102 [==============================] - 0s 63us/sample - loss: 0.4004 - accuracy: 0.8512\nEpoch 202/300\n1102/1102 [==============================] - 0s 67us/sample - loss: 0.7965 - accuracy: 0.7949\nEpoch 203/300\n1102/1102 [==============================] - 0s 67us/sample - loss: 0.7341 - accuracy: 0.7976\nEpoch 204/300\n1102/1102 [==============================] - 0s 70us/sample - loss: 0.5725 - accuracy: 0.8085\nEpoch 205/300\n1102/1102 [==============================] - 0s 69us/sample - loss: 0.4905 - accuracy: 0.8221\nEpoch 206/300\n1102/1102 [==============================] - 0s 62us/sample - loss: 0.5927 - accuracy: 0.8176\nEpoch 207/300\n1102/1102 [==============================] - 0s 66us/sample - loss: 0.4148 - accuracy: 0.8557\nEpoch 208/300\n1102/1102 [==============================] - 0s 65us/sample - loss: 0.7319 - accuracy: 0.7949\nEpoch 209/300\n1102/1102 [==============================] - 0s 71us/sample - loss: 0.6756 - accuracy: 0.7895\nEpoch 210/300\n1102/1102 [==============================] - 0s 65us/sample - loss: 0.4408 - accuracy: 0.8240\nEpoch 211/300\n1102/1102 [==============================] - 0s 67us/sample - loss: 0.4572 - accuracy: 0.8276\nEpoch 212/300\n1102/1102 [==============================] - 0s 68us/sample - loss: 0.3842 - accuracy: 0.8566\nEpoch 213/300\n1102/1102 [==============================] - 0s 69us/sample - loss: 0.4206 - accuracy: 0.8385\nEpoch 214/300\n1102/1102 [==============================] - 0s 68us/sample - loss: 0.3668 - accuracy: 0.8612\nEpoch 215/300\n1102/1102 [==============================] - 0s 67us/sample - loss: 0.4045 - accuracy: 0.8466\nEpoch 216/300\n1102/1102 [==============================] - 0s 67us/sample - loss: 0.4810 - accuracy: 0.8312\nEpoch 217/300\n1102/1102 [==============================] - 0s 67us/sample - loss: 0.4638 - accuracy: 0.8321\nEpoch 218/300\n1102/1102 [==============================] - 0s 67us/sample - loss: 0.4976 - accuracy: 0.8412\nEpoch 219/300\n1102/1102 [==============================] - 0s 65us/sample - loss: 0.4436 - accuracy: 0.8412\nEpoch 220/300\n1102/1102 [==============================] - 0s 66us/sample - loss: 0.4308 - accuracy: 0.8240\nEpoch 221/300\n1102/1102 [==============================] - 0s 69us/sample - loss: 0.4652 - accuracy: 0.8330\nEpoch 222/300\n1102/1102 [==============================] - 0s 68us/sample - loss: 0.4844 - accuracy: 0.8358\nEpoch 223/300\n1102/1102 [==============================] - 0s 65us/sample - loss: 0.3461 - accuracy: 0.8730\nEpoch 224/300\n1102/1102 [==============================] - 0s 64us/sample - loss: 0.3969 - accuracy: 0.8503\nEpoch 225/300\n1102/1102 [==============================] - 0s 73us/sample - loss: 0.4167 - accuracy: 0.8430\nEpoch 226/300\n1102/1102 [==============================] - 0s 66us/sample - loss: 0.6658 - accuracy: 0.7840\nEpoch 227/300\n1102/1102 [==============================] - 0s 65us/sample - loss: 0.6565 - accuracy: 0.8049\nEpoch 228/300\n1102/1102 [==============================] - 0s 63us/sample - loss: 0.5954 - accuracy: 0.8149\nEpoch 229/300\n1102/1102 [==============================] - 0s 66us/sample - loss: 0.4304 - accuracy: 0.8485\nEpoch 230/300\n1102/1102 [==============================] - 0s 72us/sample - loss: 0.4450 - accuracy: 0.8394\nEpoch 231/300\n1102/1102 [==============================] - 0s 68us/sample - loss: 0.4716 - accuracy: 0.8321\nEpoch 232/300\n1102/1102 [==============================] - 0s 66us/sample - loss: 0.4792 - accuracy: 0.8276\nEpoch 233/300\n1102/1102 [==============================] - 0s 66us/sample - loss: 0.4079 - accuracy: 0.8548\nEpoch 234/300\n1102/1102 [==============================] - 0s 65us/sample - loss: 0.4913 - accuracy: 0.8267\nEpoch 235/300\n1102/1102 [==============================] - 0s 65us/sample - loss: 0.4319 - accuracy: 0.8475\nEpoch 236/300\n1102/1102 [==============================] - 0s 63us/sample - loss: 0.3926 - accuracy: 0.8530\nEpoch 237/300\n1102/1102 [==============================] - 0s 64us/sample - loss: 0.6507 - accuracy: 0.8013\nEpoch 238/300\n1102/1102 [==============================] - 0s 63us/sample - loss: 0.9553 - accuracy: 0.7913\nEpoch 239/300\n1102/1102 [==============================] - 0s 62us/sample - loss: 0.5876 - accuracy: 0.8149\nEpoch 240/300\n1102/1102 [==============================] - 0s 60us/sample - loss: 0.4628 - accuracy: 0.8267\nEpoch 241/300\n1102/1102 [==============================] - 0s 63us/sample - loss: 0.4631 - accuracy: 0.8376\nEpoch 242/300\n1102/1102 [==============================] - 0s 61us/sample - loss: 0.8819 - accuracy: 0.7777\nEpoch 243/300\n1102/1102 [==============================] - 0s 64us/sample - loss: 0.5605 - accuracy: 0.8194\nEpoch 244/300\n1102/1102 [==============================] - 0s 65us/sample - loss: 0.4650 - accuracy: 0.8312\nEpoch 245/300\n1102/1102 [==============================] - 0s 63us/sample - loss: 1.1021 - accuracy: 0.7704\nEpoch 246/300\n1102/1102 [==============================] - 0s 63us/sample - loss: 0.6024 - accuracy: 0.8022\nEpoch 247/300\n1102/1102 [==============================] - 0s 63us/sample - loss: 0.4128 - accuracy: 0.8530\nEpoch 248/300\n1102/1102 [==============================] - 0s 62us/sample - loss: 0.4077 - accuracy: 0.8548\nEpoch 249/300\n1102/1102 [==============================] - 0s 60us/sample - loss: 0.5001 - accuracy: 0.8285\nEpoch 250/300\n1102/1102 [==============================] - 0s 73us/sample - loss: 0.5949 - accuracy: 0.7913\nEpoch 251/300\n1102/1102 [==============================] - 0s 60us/sample - loss: 0.4338 - accuracy: 0.8475\nEpoch 252/300\n1102/1102 [==============================] - 0s 62us/sample - loss: 0.4355 - accuracy: 0.8358\nEpoch 253/300\n1102/1102 [==============================] - 0s 63us/sample - loss: 0.5681 - accuracy: 0.8103\nEpoch 254/300\n1102/1102 [==============================] - 0s 63us/sample - loss: 0.4357 - accuracy: 0.8403\nEpoch 255/300\n1102/1102 [==============================] - 0s 64us/sample - loss: 0.4155 - accuracy: 0.8475\nEpoch 256/300\n1102/1102 [==============================] - 0s 62us/sample - loss: 0.4086 - accuracy: 0.8566\nEpoch 257/300\n1102/1102 [==============================] - 0s 64us/sample - loss: 0.6476 - accuracy: 0.7949\nEpoch 258/300\n1102/1102 [==============================] - 0s 64us/sample - loss: 0.5324 - accuracy: 0.8185\nEpoch 259/300\n1102/1102 [==============================] - 0s 66us/sample - loss: 0.5664 - accuracy: 0.8240\nEpoch 260/300\n1102/1102 [==============================] - 0s 64us/sample - loss: 0.4035 - accuracy: 0.8512\nEpoch 261/300\n1102/1102 [==============================] - 0s 68us/sample - loss: 0.5851 - accuracy: 0.8131\nEpoch 262/300\n1102/1102 [==============================] - 0s 70us/sample - loss: 0.4633 - accuracy: 0.8358\nEpoch 263/300\n1102/1102 [==============================] - 0s 76us/sample - loss: 0.5972 - accuracy: 0.8094\nEpoch 264/300\n1102/1102 [==============================] - 0s 67us/sample - loss: 0.4650 - accuracy: 0.8376\nEpoch 265/300\n1102/1102 [==============================] - 0s 66us/sample - loss: 0.4933 - accuracy: 0.8249\nEpoch 266/300\n1102/1102 [==============================] - 0s 64us/sample - loss: 0.4685 - accuracy: 0.8348\nEpoch 267/300\n1102/1102 [==============================] - 0s 69us/sample - loss: 0.9728 - accuracy: 0.7686\nEpoch 268/300\n1102/1102 [==============================] - 0s 71us/sample - loss: 0.4018 - accuracy: 0.8494\nEpoch 269/300\n1102/1102 [==============================] - 0s 67us/sample - loss: 0.5001 - accuracy: 0.8249\nEpoch 270/300\n1102/1102 [==============================] - 0s 71us/sample - loss: 0.6506 - accuracy: 0.8085\nEpoch 271/300\n1102/1102 [==============================] - 0s 65us/sample - loss: 0.5322 - accuracy: 0.8267\nEpoch 272/300\n1102/1102 [==============================] - 0s 66us/sample - loss: 0.4706 - accuracy: 0.8439\nEpoch 273/300\n1102/1102 [==============================] - 0s 65us/sample - loss: 0.6702 - accuracy: 0.8022\nEpoch 274/300\n1102/1102 [==============================] - 0s 67us/sample - loss: 0.4813 - accuracy: 0.8339\nEpoch 275/300\n1102/1102 [==============================] - 0s 71us/sample - loss: 0.6239 - accuracy: 0.8185\nEpoch 276/300\n1102/1102 [==============================] - 0s 70us/sample - loss: 0.7025 - accuracy: 0.7958\nEpoch 277/300\n1102/1102 [==============================] - 0s 67us/sample - loss: 0.4474 - accuracy: 0.8421\nEpoch 278/300\n1102/1102 [==============================] - 0s 64us/sample - loss: 0.4110 - accuracy: 0.8448\nEpoch 279/300\n1102/1102 [==============================] - 0s 66us/sample - loss: 0.4446 - accuracy: 0.8457\nEpoch 280/300\n1102/1102 [==============================] - 0s 62us/sample - loss: 0.3948 - accuracy: 0.8503\nEpoch 281/300\n1102/1102 [==============================] - 0s 64us/sample - loss: 0.4153 - accuracy: 0.8539\nEpoch 282/300\n1102/1102 [==============================] - 0s 66us/sample - loss: 0.4024 - accuracy: 0.8421\nEpoch 283/300\n1102/1102 [==============================] - 0s 67us/sample - loss: 0.4170 - accuracy: 0.8421\nEpoch 284/300\n1102/1102 [==============================] - 0s 66us/sample - loss: 0.4024 - accuracy: 0.8485\nEpoch 285/300\n1102/1102 [==============================] - 0s 64us/sample - loss: 0.3899 - accuracy: 0.8494\nEpoch 286/300\n1102/1102 [==============================] - 0s 66us/sample - loss: 0.8039 - accuracy: 0.7777\nEpoch 287/300\n1102/1102 [==============================] - 0s 64us/sample - loss: 0.5949 - accuracy: 0.8267\nEpoch 288/300\n1102/1102 [==============================] - 0s 65us/sample - loss: 0.6367 - accuracy: 0.8040\nEpoch 289/300\n1102/1102 [==============================] - 0s 68us/sample - loss: 0.4167 - accuracy: 0.8512\nEpoch 290/300\n1102/1102 [==============================] - 0s 70us/sample - loss: 0.4578 - accuracy: 0.8312\nEpoch 291/300\n1102/1102 [==============================] - 0s 67us/sample - loss: 0.5906 - accuracy: 0.8131\nEpoch 292/300\n1102/1102 [==============================] - 0s 68us/sample - loss: 0.3842 - accuracy: 0.8521\nEpoch 293/300\n1102/1102 [==============================] - 0s 68us/sample - loss: 0.3747 - accuracy: 0.8593\nEpoch 294/300\n1102/1102 [==============================] - 0s 69us/sample - loss: 0.4692 - accuracy: 0.8294\nEpoch 295/300\n1102/1102 [==============================] - 0s 68us/sample - loss: 0.3674 - accuracy: 0.8639\nEpoch 296/300\n1102/1102 [==============================] - 0s 66us/sample - loss: 0.4059 - accuracy: 0.8485\nEpoch 297/300\n1102/1102 [==============================] - 0s 63us/sample - loss: 0.5351 - accuracy: 0.8203\nEpoch 298/300\n1102/1102 [==============================] - 0s 62us/sample - loss: 0.4025 - accuracy: 0.8593\nEpoch 299/300\n1102/1102 [==============================] - 0s 67us/sample - loss: 0.4610 - accuracy: 0.8457\nEpoch 300/300\n1102/1102 [==============================] - 0s 68us/sample - loss: 0.3679 - accuracy: 0.8566\n"
    }
   ],
   "source": [
    "#Train the Model\n",
    "fit_model = nn.fit(X_train,y_train,epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "368/1 - 0s - loss: 2.2484 - accuracy: 0.8832\nloss: 1.86841786166896, Accuracy: 0.883152186870575\n"
    }
   ],
   "source": [
    "# Evaluate the model using test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_3 (Dense)              (None, 8)                 448       \n_________________________________________________________________\ndense_4 (Dense)              (None, 8)                 72        \n_________________________________________________________________\ndense_5 (Dense)              (None, 1)                 9         \n=================================================================\nTotal params: 529\nTrainable params: 529\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "## Skill drill: test different Models\n",
    "\n",
    "#Define the model - deep neural net\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 =  8\n",
    "hidden_nodes_layer2 = 8\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\")\n",
    ")\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": " - accuracy: 0.8294\nEpoch 116/300\n1102/1102 [==============================] - 0s 62us/sample - loss: 0.4514 - accuracy: 0.8339\nEpoch 117/300\n1102/1102 [==============================] - 0s 63us/sample - loss: 0.4233 - accuracy: 0.8421\nEpoch 118/300\n1102/1102 [==============================] - 0s 62us/sample - loss: 0.3962 - accuracy: 0.8512\nEpoch 119/300\n1102/1102 [==============================] - 0s 63us/sample - loss: 0.4122 - accuracy: 0.8303\nEpoch 120/300\n1102/1102 [==============================] - 0s 65us/sample - loss: 0.6972 - accuracy: 0.7967\nEpoch 121/300\n1102/1102 [==============================] - 0s 64us/sample - loss: 0.5463 - accuracy: 0.8240\nEpoch 122/300\n1102/1102 [==============================] - 0s 63us/sample - loss: 0.4990 - accuracy: 0.8348\nEpoch 123/300\n1102/1102 [==============================] - 0s 65us/sample - loss: 0.4215 - accuracy: 0.8421\nEpoch 124/300\n1102/1102 [==============================] - 0s 63us/sample - loss: 0.3811 - accuracy: 0.8485\nEpoch 125/300\n1102/1102 [==============================] - 0s 59us/sample - loss: 0.4898 - accuracy: 0.8394\nEpoch 126/300\n1102/1102 [==============================] - 0s 64us/sample - loss: 0.3754 - accuracy: 0.8521\nEpoch 127/300\n1102/1102 [==============================] - 0s 62us/sample - loss: 0.3941 - accuracy: 0.8457\nEpoch 128/300\n1102/1102 [==============================] - 0s 64us/sample - loss: 0.4232 - accuracy: 0.8412\nEpoch 129/300\n1102/1102 [==============================] - 0s 64us/sample - loss: 0.3850 - accuracy: 0.8521\nEpoch 130/300\n1102/1102 [==============================] - 0s 69us/sample - loss: 0.4568 - accuracy: 0.8348\nEpoch 131/300\n1102/1102 [==============================] - 0s 64us/sample - loss: 0.3708 - accuracy: 0.8630\nEpoch 132/300\n1102/1102 [==============================] - 0s 64us/sample - loss: 0.5327 - accuracy: 0.8149\nEpoch 133/300\n1102/1102 [==============================] - 0s 65us/sample - loss: 0.5953 - accuracy: 0.8058\nEpoch 134/300\n1102/1102 [==============================] - 0s 65us/sample - loss: 0.6749 - accuracy: 0.7949\nEpoch 135/300\n1102/1102 [==============================] - 0s 61us/sample - loss: 0.7225 - accuracy: 0.8031\nEpoch 136/300\n1102/1102 [==============================] - 0s 65us/sample - loss: 0.4057 - accuracy: 0.8394\nEpoch 137/300\n1102/1102 [==============================] - 0s 65us/sample - loss: 0.3536 - accuracy: 0.8612\nEpoch 138/300\n1102/1102 [==============================] - 0s 64us/sample - loss: 0.4808 - accuracy: 0.8249\nEpoch 139/300\n1102/1102 [==============================] - 0s 63us/sample - loss: 0.3445 - accuracy: 0.8612\nEpoch 140/300\n1102/1102 [==============================] - 0s 65us/sample - loss: 0.3494 - accuracy: 0.8621\nEpoch 141/300\n1102/1102 [==============================] - 0s 69us/sample - loss: 0.3422 - accuracy: 0.8657\nEpoch 142/300\n1102/1102 [==============================] - 0s 68us/sample - loss: 0.4353 - accuracy: 0.8339\nEpoch 143/300\n1102/1102 [==============================] - 0s 62us/sample - loss: 0.4798 - accuracy: 0.8212\nEpoch 144/300\n1102/1102 [==============================] - 0s 57us/sample - loss: 0.3864 - accuracy: 0.8584\nEpoch 145/300\n1102/1102 [==============================] - 0s 61us/sample - loss: 0.3446 - accuracy: 0.8721\nEpoch 146/300\n1102/1102 [==============================] - 0s 58us/sample - loss: 0.4063 - accuracy: 0.8439\nEpoch 147/300\n1102/1102 [==============================] - 0s 58us/sample - loss: 0.3507 - accuracy: 0.8657\nEpoch 148/300\n1102/1102 [==============================] - 0s 60us/sample - loss: 0.3384 - accuracy: 0.8675\nEpoch 149/300\n1102/1102 [==============================] - 0s 63us/sample - loss: 0.3823 - accuracy: 0.8675\nEpoch 150/300\n1102/1102 [==============================] - 0s 64us/sample - loss: 0.4257 - accuracy: 0.8285\nEpoch 151/300\n1102/1102 [==============================] - 0s 60us/sample - loss: 0.3753 - accuracy: 0.8466\nEpoch 152/300\n1102/1102 [==============================] - 0s 60us/sample - loss: 0.4028 - accuracy: 0.8448\nEpoch 153/300\n1102/1102 [==============================] - 0s 63us/sample - loss: 0.3414 - accuracy: 0.8666\nEpoch 154/300\n1102/1102 [==============================] - 0s 65us/sample - loss: 0.3893 - accuracy: 0.8539\nEpoch 155/300\n1102/1102 [==============================] - 0s 63us/sample - loss: 0.3412 - accuracy: 0.8657\nEpoch 156/300\n1102/1102 [==============================] - 0s 65us/sample - loss: 0.3546 - accuracy: 0.8775\nEpoch 157/300\n1102/1102 [==============================] - 0s 63us/sample - loss: 0.4277 - accuracy: 0.8385\nEpoch 158/300\n1102/1102 [==============================] - 0s 66us/sample - loss: 0.3755 - accuracy: 0.8575\nEpoch 159/300\n1102/1102 [==============================] - 0s 65us/sample - loss: 0.3965 - accuracy: 0.8521\nEpoch 160/300\n1102/1102 [==============================] - 0s 77us/sample - loss: 0.3632 - accuracy: 0.8621\nEpoch 161/300\n1102/1102 [==============================] - 0s 62us/sample - loss: 0.4099 - accuracy: 0.8439\nEpoch 162/300\n1102/1102 [==============================] - 0s 63us/sample - loss: 0.3962 - accuracy: 0.8702\nEpoch 163/300\n1102/1102 [==============================] - 0s 64us/sample - loss: 0.3486 - accuracy: 0.8548\nEpoch 164/300\n1102/1102 [==============================] - 0s 68us/sample - loss: 0.3889 - accuracy: 0.8448\nEpoch 165/300\n1102/1102 [==============================] - 0s 65us/sample - loss: 0.6377 - accuracy: 0.8076\nEpoch 166/300\n1102/1102 [==============================] - 0s 65us/sample - loss: 0.4627 - accuracy: 0.8203\nEpoch 167/300\n1102/1102 [==============================] - 0s 68us/sample - loss: 0.3725 - accuracy: 0.8657\nEpoch 168/300\n1102/1102 [==============================] - 0s 67us/sample - loss: 0.3638 - accuracy: 0.8639\nEpoch 169/300\n1102/1102 [==============================] - 0s 65us/sample - loss: 0.4813 - accuracy: 0.8294\nEpoch 170/300\n1102/1102 [==============================] - 0s 72us/sample - loss: 0.5743 - accuracy: 0.8149\nEpoch 171/300\n1102/1102 [==============================] - 0s 70us/sample - loss: 0.3727 - accuracy: 0.8448\nEpoch 172/300\n1102/1102 [==============================] - 0s 69us/sample - loss: 0.4039 - accuracy: 0.8512\nEpoch 173/300\n1102/1102 [==============================] - 0s 69us/sample - loss: 0.5426 - accuracy: 0.8249\nEpoch 174/300\n1102/1102 [==============================] - 0s 67us/sample - loss: 0.5080 - accuracy: 0.8067\nEpoch 175/300\n1102/1102 [==============================] - 0s 67us/sample - loss: 0.4029 - accuracy: 0.8621\nEpoch 176/300\n1102/1102 [==============================] - 0s 69us/sample - loss: 0.3964 - accuracy: 0.8584\nEpoch 177/300\n1102/1102 [==============================] - 0s 69us/sample - loss: 0.3725 - accuracy: 0.8593\nEpoch 178/300\n1102/1102 [==============================] - 0s 68us/sample - loss: 0.3335 - accuracy: 0.8766\nEpoch 179/300\n1102/1102 [==============================] - 0s 68us/sample - loss: 0.4411 - accuracy: 0.8348\nEpoch 180/300\n1102/1102 [==============================] - 0s 66us/sample - loss: 0.3810 - accuracy: 0.8539\nEpoch 181/300\n1102/1102 [==============================] - 0s 65us/sample - loss: 0.4235 - accuracy: 0.8512\nEpoch 182/300\n1102/1102 [==============================] - 0s 65us/sample - loss: 0.5162 - accuracy: 0.8167\nEpoch 183/300\n1102/1102 [==============================] - 0s 66us/sample - loss: 0.4309 - accuracy: 0.8339\nEpoch 184/300\n1102/1102 [==============================] - 0s 66us/sample - loss: 0.3770 - accuracy: 0.8684\nEpoch 185/300\n1102/1102 [==============================] - 0s 66us/sample - loss: 0.3917 - accuracy: 0.8557\nEpoch 186/300\n1102/1102 [==============================] - 0s 64us/sample - loss: 0.3476 - accuracy: 0.8566\nEpoch 187/300\n1102/1102 [==============================] - 0s 65us/sample - loss: 0.4338 - accuracy: 0.8376\nEpoch 188/300\n1102/1102 [==============================] - 0s 77us/sample - loss: 0.3943 - accuracy: 0.8421\nEpoch 189/300\n1102/1102 [==============================] - 0s 69us/sample - loss: 0.3630 - accuracy: 0.8603\nEpoch 190/300\n1102/1102 [==============================] - 0s 68us/sample - loss: 0.4585 - accuracy: 0.8385\nEpoch 191/300\n1102/1102 [==============================] - 0s 65us/sample - loss: 0.4124 - accuracy: 0.8321\nEpoch 192/300\n1102/1102 [==============================] - 0s 67us/sample - loss: 0.5231 - accuracy: 0.8131\nEpoch 193/300\n1102/1102 [==============================] - 0s 65us/sample - loss: 0.3888 - accuracy: 0.8603\nEpoch 194/300\n1102/1102 [==============================] - 0s 67us/sample - loss: 0.4456 - accuracy: 0.8430\nEpoch 195/300\n1102/1102 [==============================] - 0s 65us/sample - loss: 0.4173 - accuracy: 0.8457\nEpoch 196/300\n1102/1102 [==============================] - 0s 65us/sample - loss: 0.3281 - accuracy: 0.8757\nEpoch 197/300\n1102/1102 [==============================] - 0s 66us/sample - loss: 0.3710 - accuracy: 0.8603\nEpoch 198/300\n1102/1102 [==============================] - 0s 68us/sample - loss: 0.3923 - accuracy: 0.8466\nEpoch 199/300\n1102/1102 [==============================] - 0s 67us/sample - loss: 0.4271 - accuracy: 0.8367\nEpoch 200/300\n1102/1102 [==============================] - 0s 66us/sample - loss: 0.4173 - accuracy: 0.8348\nEpoch 201/300\n1102/1102 [==============================] - 0s 65us/sample - loss: 0.4198 - accuracy: 0.8412\nEpoch 202/300\n1102/1102 [==============================] - 0s 67us/sample - loss: 0.3478 - accuracy: 0.8693\nEpoch 203/300\n1102/1102 [==============================] - 0s 65us/sample - loss: 0.3386 - accuracy: 0.8711\nEpoch 204/300\n1102/1102 [==============================] - 0s 67us/sample - loss: 0.3679 - accuracy: 0.8603\nEpoch 205/300\n1102/1102 [==============================] - 0s 66us/sample - loss: 0.4180 - accuracy: 0.8530\nEpoch 206/300\n1102/1102 [==============================] - 0s 64us/sample - loss: 0.3451 - accuracy: 0.8657\nEpoch 207/300\n1102/1102 [==============================] - 0s 66us/sample - loss: 0.3923 - accuracy: 0.8503\nEpoch 208/300\n1102/1102 [==============================] - 0s 66us/sample - loss: 0.3689 - accuracy: 0.8748\nEpoch 209/300\n1102/1102 [==============================] - 0s 66us/sample - loss: 0.3808 - accuracy: 0.8539\nEpoch 210/300\n1102/1102 [==============================] - 0s 66us/sample - loss: 0.3572 - accuracy: 0.8639\nEpoch 211/300\n1102/1102 [==============================] - 0s 65us/sample - loss: 0.3903 - accuracy: 0.8530\nEpoch 212/300\n1102/1102 [==============================] - 0s 67us/sample - loss: 0.4069 - accuracy: 0.8403\nEpoch 213/300\n1102/1102 [==============================] - 0s 65us/sample - loss: 0.3819 - accuracy: 0.8548\nEpoch 214/300\n1102/1102 [==============================] - 0s 67us/sample - loss: 0.4063 - accuracy: 0.8485\nEpoch 215/300\n1102/1102 [==============================] - 0s 61us/sample - loss: 0.3597 - accuracy: 0.8666\nEpoch 216/300\n1102/1102 [==============================] - 0s 67us/sample - loss: 0.3604 - accuracy: 0.8530\nEpoch 217/300\n1102/1102 [==============================] - 0s 67us/sample - loss: 0.3720 - accuracy: 0.8430\nEpoch 218/300\n1102/1102 [==============================] - 0s 67us/sample - loss: 0.4100 - accuracy: 0.8430\nEpoch 219/300\n1102/1102 [==============================] - 0s 66us/sample - loss: 0.5665 - accuracy: 0.8140\nEpoch 220/300\n1102/1102 [==============================] - 0s 66us/sample - loss: 0.6356 - accuracy: 0.8158\nEpoch 221/300\n1102/1102 [==============================] - 0s 65us/sample - loss: 0.3529 - accuracy: 0.8648\nEpoch 222/300\n1102/1102 [==============================] - 0s 68us/sample - loss: 0.4613 - accuracy: 0.8512\nEpoch 223/300\n1102/1102 [==============================] - 0s 65us/sample - loss: 0.5467 - accuracy: 0.8158\nEpoch 224/300\n1102/1102 [==============================] - 0s 63us/sample - loss: 0.3625 - accuracy: 0.8575\nEpoch 225/300\n1102/1102 [==============================] - 0s 66us/sample - loss: 0.3945 - accuracy: 0.8512\nEpoch 226/300\n1102/1102 [==============================] - 0s 66us/sample - loss: 0.5807 - accuracy: 0.8122\nEpoch 227/300\n1102/1102 [==============================] - 0s 63us/sample - loss: 0.3481 - accuracy: 0.8702\nEpoch 228/300\n1102/1102 [==============================] - 0s 65us/sample - loss: 0.5423 - accuracy: 0.8140\nEpoch 229/300\n1102/1102 [==============================] - 0s 65us/sample - loss: 0.5663 - accuracy: 0.8058\nEpoch 230/300\n1102/1102 [==============================] - 0s 64us/sample - loss: 0.4289 - accuracy: 0.8448\nEpoch 231/300\n1102/1102 [==============================] - 0s 64us/sample - loss: 0.3877 - accuracy: 0.8394\nEpoch 232/300\n1102/1102 [==============================] - 0s 67us/sample - loss: 0.5342 - accuracy: 0.8004\nEpoch 233/300\n1102/1102 [==============================] - 0s 65us/sample - loss: 0.7710 - accuracy: 0.7768\nEpoch 234/300\n1102/1102 [==============================] - 0s 68us/sample - loss: 0.3980 - accuracy: 0.8512\nEpoch 235/300\n1102/1102 [==============================] - 0s 65us/sample - loss: 0.3518 - accuracy: 0.8639\nEpoch 236/300\n1102/1102 [==============================] - 0s 80us/sample - loss: 0.4188 - accuracy: 0.8466\nEpoch 237/300\n1102/1102 [==============================] - 0s 68us/sample - loss: 0.3702 - accuracy: 0.8603\nEpoch 238/300\n1102/1102 [==============================] - 0s 65us/sample - loss: 0.4716 - accuracy: 0.8367\nEpoch 239/300\n1102/1102 [==============================] - 0s 67us/sample - loss: 0.3718 - accuracy: 0.8475\nEpoch 240/300\n1102/1102 [==============================] - 0s 66us/sample - loss: 0.4487 - accuracy: 0.8403\nEpoch 241/300\n1102/1102 [==============================] - 0s 66us/sample - loss: 0.4626 - accuracy: 0.8376\nEpoch 242/300\n1102/1102 [==============================] - 0s 66us/sample - loss: 0.4009 - accuracy: 0.8412\nEpoch 243/300\n1102/1102 [==============================] - 0s 65us/sample - loss: 0.3797 - accuracy: 0.8584\nEpoch 244/300\n1102/1102 [==============================] - 0s 64us/sample - loss: 0.3555 - accuracy: 0.8648\nEpoch 245/300\n1102/1102 [==============================] - 0s 65us/sample - loss: 0.3639 - accuracy: 0.8630\nEpoch 246/300\n1102/1102 [==============================] - 0s 70us/sample - loss: 0.3995 - accuracy: 0.8439\nEpoch 247/300\n1102/1102 [==============================] - 0s 63us/sample - loss: 0.3561 - accuracy: 0.8630\nEpoch 248/300\n1102/1102 [==============================] - 0s 65us/sample - loss: 0.3839 - accuracy: 0.8557\nEpoch 249/300\n1102/1102 [==============================] - 0s 64us/sample - loss: 0.4360 - accuracy: 0.8376\nEpoch 250/300\n1102/1102 [==============================] - 0s 65us/sample - loss: 0.4222 - accuracy: 0.8439\nEpoch 251/300\n1102/1102 [==============================] - 0s 64us/sample - loss: 0.4845 - accuracy: 0.8249\nEpoch 252/300\n1102/1102 [==============================] - 0s 65us/sample - loss: 0.3403 - accuracy: 0.8657\nEpoch 253/300\n1102/1102 [==============================] - 0s 64us/sample - loss: 0.3501 - accuracy: 0.8621\nEpoch 254/300\n1102/1102 [==============================] - 0s 63us/sample - loss: 0.5052 - accuracy: 0.8258\nEpoch 255/300\n1102/1102 [==============================] - 0s 62us/sample - loss: 0.3805 - accuracy: 0.8548\nEpoch 256/300\n1102/1102 [==============================] - 0s 63us/sample - loss: 0.3525 - accuracy: 0.8584\nEpoch 257/300\n1102/1102 [==============================] - 0s 63us/sample - loss: 0.3528 - accuracy: 0.8639\nEpoch 258/300\n1102/1102 [==============================] - 0s 64us/sample - loss: 0.3623 - accuracy: 0.8430\nEpoch 259/300\n1102/1102 [==============================] - 0s 63us/sample - loss: 0.3768 - accuracy: 0.8430\nEpoch 260/300\n1102/1102 [==============================] - 0s 63us/sample - loss: 0.3570 - accuracy: 0.8566\nEpoch 261/300\n1102/1102 [==============================] - 0s 63us/sample - loss: 0.4336 - accuracy: 0.8294\nEpoch 262/300\n1102/1102 [==============================] - 0s 63us/sample - loss: 0.3807 - accuracy: 0.8403\nEpoch 263/300\n1102/1102 [==============================] - 0s 62us/sample - loss: 0.3674 - accuracy: 0.8593\nEpoch 264/300\n1102/1102 [==============================] - 0s 64us/sample - loss: 0.3534 - accuracy: 0.8603\nEpoch 265/300\n1102/1102 [==============================] - 0s 62us/sample - loss: 0.3609 - accuracy: 0.8566\nEpoch 266/300\n1102/1102 [==============================] - 0s 61us/sample - loss: 0.3516 - accuracy: 0.8657\nEpoch 267/300\n1102/1102 [==============================] - 0s 61us/sample - loss: 0.4112 - accuracy: 0.8339\nEpoch 268/300\n1102/1102 [==============================] - 0s 60us/sample - loss: 0.3562 - accuracy: 0.8657\nEpoch 269/300\n1102/1102 [==============================] - 0s 58us/sample - loss: 0.3747 - accuracy: 0.8512\nEpoch 270/300\n1102/1102 [==============================] - 0s 65us/sample - loss: 0.4480 - accuracy: 0.8312\nEpoch 271/300\n1102/1102 [==============================] - 0s 64us/sample - loss: 0.4670 - accuracy: 0.8367\nEpoch 272/300\n1102/1102 [==============================] - 0s 67us/sample - loss: 0.3749 - accuracy: 0.8521\nEpoch 273/300\n1102/1102 [==============================] - 0s 64us/sample - loss: 0.3922 - accuracy: 0.8503\nEpoch 274/300\n1102/1102 [==============================] - 0s 64us/sample - loss: 0.3808 - accuracy: 0.8521\nEpoch 275/300\n1102/1102 [==============================] - 0s 64us/sample - loss: 0.3423 - accuracy: 0.8630\nEpoch 276/300\n1102/1102 [==============================] - 0s 59us/sample - loss: 0.4066 - accuracy: 0.8421\nEpoch 277/300\n1102/1102 [==============================] - 0s 64us/sample - loss: 0.3669 - accuracy: 0.8530\nEpoch 278/300\n1102/1102 [==============================] - 0s 65us/sample - loss: 0.3402 - accuracy: 0.8675\nEpoch 279/300\n1102/1102 [==============================] - 0s 71us/sample - loss: 0.3884 - accuracy: 0.8494\nEpoch 280/300\n1102/1102 [==============================] - 0s 67us/sample - loss: 0.3451 - accuracy: 0.8657\nEpoch 281/300\n1102/1102 [==============================] - 0s 64us/sample - loss: 0.3549 - accuracy: 0.8566\nEpoch 282/300\n1102/1102 [==============================] - 0s 68us/sample - loss: 0.3491 - accuracy: 0.8621\nEpoch 283/300\n1102/1102 [==============================] - 0s 67us/sample - loss: 0.4396 - accuracy: 0.8240\nEpoch 284/300\n1102/1102 [==============================] - 0s 67us/sample - loss: 0.3485 - accuracy: 0.8603\nEpoch 285/300\n1102/1102 [==============================] - 0s 67us/sample - loss: 0.3156 - accuracy: 0.8711\nEpoch 286/300\n1102/1102 [==============================] - 0s 66us/sample - loss: 0.3587 - accuracy: 0.8603\nEpoch 287/300\n1102/1102 [==============================] - 0s 65us/sample - loss: 0.3600 - accuracy: 0.8557\nEpoch 288/300\n1102/1102 [==============================] - 0s 64us/sample - loss: 0.3927 - accuracy: 0.8403\nEpoch 289/300\n1102/1102 [==============================] - 0s 63us/sample - loss: 0.3274 - accuracy: 0.8721\nEpoch 290/300\n1102/1102 [==============================] - 0s 62us/sample - loss: 0.3316 - accuracy: 0.8711\nEpoch 291/300\n1102/1102 [==============================] - 0s 66us/sample - loss: 0.4149 - accuracy: 0.8448\nEpoch 292/300\n1102/1102 [==============================] - 0s 67us/sample - loss: 0.3734 - accuracy: 0.8421\nEpoch 293/300\n1102/1102 [==============================] - 0s 65us/sample - loss: 0.3675 - accuracy: 0.8512\nEpoch 294/300\n1102/1102 [==============================] - 0s 66us/sample - loss: 0.3649 - accuracy: 0.8657\nEpoch 295/300\n1102/1102 [==============================] - 0s 64us/sample - loss: 0.3897 - accuracy: 0.8457\nEpoch 296/300\n1102/1102 [==============================] - 0s 67us/sample - loss: 0.4200 - accuracy: 0.8385\nEpoch 297/300\n1102/1102 [==============================] - 0s 65us/sample - loss: 0.3816 - accuracy: 0.8439\nEpoch 298/300\n1102/1102 [==============================] - 0s 67us/sample - loss: 0.3729 - accuracy: 0.8612\nEpoch 299/300\n1102/1102 [==============================] - 0s 65us/sample - loss: 0.4878 - accuracy: 0.8122\nEpoch 300/300\n1102/1102 [==============================] - 0s 66us/sample - loss: 0.5036 - accuracy: 0.8267\n"
    }
   ],
   "source": [
    "#Train the Model\n",
    "fit_model = nn.fit(X_train,y_train,epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "368/1 - 0s - loss: 2.1786 - accuracy: 0.8641\nloss: 1.7955526865046958, Accuracy: 0.864130437374115\n"
    }
   ],
   "source": [
    "# Evaluate the model using test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test,y_test,verbose=2)\n",
    "print(f\"loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1602732197224",
   "display_name": "Python 3.7.7 64-bit ('PythonData': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}